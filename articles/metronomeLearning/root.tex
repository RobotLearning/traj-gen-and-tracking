% Temporarily as a seperate document
% Will be placed inside the IROS root latex file

\documentclass[10pt,a4paper]{article}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{color}
\usepackage{hyperref}

% theorem environment
\newtheorem{prop}{Proposition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{prop2}{Proposition}
\newtheorem{lem}{Lemma} 
\newtheorem{ex}{Example}

% For algorithms
\usepackage{algorithm}
\usepackage{algorithmic}

% custom commands
\newcommand\at[2]{\left.#1\right|_{#2}} % the at differential sign
\newcommand\scalemath[2]{\scalebox{#1}{\mbox{\ensuremath{\displaystyle #2}}}} % scaling matrices

%% custom macros
\newcommand{\todo}{\textcolor{red}{TODO}} % TODO!
\newcommand{\kin}{\mathcal{T}} % used to denote inverse kinematics
\newcommand{\invKin}{\mathcal{T}^{-1}} % used to denote inverse kinematics

\newcommand{\joint}{q} % used to denote robot state in joint space
\newcommand{\state}{\bar{\joint}} % denotes the generalized coordinates - joint space and velocity coordinates
\newcommand{\dmp}{s} % used to denote the dmp trajectory states
\newcommand{\error}{e} % difference between state and reference
\newcommand{\traj}{r} % used to denote the points on the trajectory to be tracked

\newcommand{\dist}{\epsilon} % denotes the disturbances acting on the rigid body dynamics
\newcommand{\linDist}{d} % denotes the disturbances on the LTV model

\newcommand{\sysInput}{u} % used to denote the system inputs
\newcommand{\linInput}{\tilde{u}} % denotes the LTV inputs
\newcommand{\trjInput}{\nu} % denotes the inputs on the trajectory


% % % % DMP terminology % % % %
\newcommand{\fullvec}{\psi} % full vector for state-ref-dmp-goal
\newcommand{\force}{f} % forcing term of the dmps
\newcommand{\phase}{x} % phase of the dmp
\newcommand{\weights}{w} % weights of the dmp
\newcommand{\basis}{\phi} % basis functions of the dmp as a matrix

% % % % ILC terminology % % % %
\newcommand{\qmatrix}{\Gamma} % denotes the filtering qmatrix term of Bristow et al.
\newcommand{\lmatrix}{L} % denotes the learning matrix of Bristow et al.

\newcommand{\observations}{\mathbf{y}} % used for the observed output
\newcommand{\dynamics}{f}
\newcommand{\dynamicsNominal}{f_{\mathrm{nom}}}
\newcommand{\policy}{\mathbf{\pi}}
\newcommand{\ValueFunction}{J}
\newcommand{\episode}{k} % used for episode number

\newcommand{\totalTime}{T} % total time duration 
\newcommand{\numSteps}{N} % total number of time steps
\newcommand{\numepisode}{K} % total number of episodes

\newcommand{\threshold}{\epsilon}
\newcommand{\alg}{\emph{wILC}}
\newcommand{\dataset}{E}

% Set the paths where all figures are taken from:
\graphicspath{{Pictures/}}
\mathtoolsset{showonlyrefs} 
\newcommand{\includesvg}[1]{%
% \executeiffilenewer{#1.svg}{#1.pdf}%
% {inkscape -z -D --file=#1.svg %
% --export-pdf=#1.pdf --export-latex}%
 \input{#1.pdf_tex}%
}

\author{Okan Ko\c c, Guilherme Maeda, Gerhard Neumann and Jan Peters}
\title{Optimal Striking Movement Representation \& Execution}
\begin{document}
\maketitle


\section{Metronome learning}

% These are exciting times for robotics research!

It is possible to incorporate one of the advantages of the DMP framework, the \emph{slowing-down} effect with the help of the error coupling term \cite{Schaal07}, \cite{Ijspeert13}

% maybe represent r as a dmp
\begin{equation}
\dot{\phase} = \frac{-\tau\alpha\phase}{(\state - \traj)^2}
\label{phaseWithErrorCoupling}
\end{equation}

in the ILC framework by including feedforward adjustment on the time constant $\alpha$:

% Geri's comment: active learning and particularly artificial curiosity can be relevant here
\begin{equation}
\begin{aligned}
\phase_{\log} &:= \log(\phase) \\
\dot{\phase}_{log} &= -\tau\alpha
\label{logPhase}
\end{aligned}
\end{equation}

which can be motivated again using gradient descent on the cost functional with the variable end-point

\begin{equation}
\begin{aligned}
J(\weights,T(\alpha)) &= \int_{0}^{T} (\state - \traj)^{\mathrm{T}}Q(k)(\state - \traj) + \weights^{\mathrm{T}}R_w(k)\weights \ \mathrm{d}t + (\state_T-\traj_T)^{\mathrm{T}}Q_{T}(\state_T-\traj_T) 
\end{aligned}
\label{costTimeVarying}
\end{equation}

The gradient of \eqref{costTimeVarying} can be resolved using the calculus of variations. This gives us a discretization-free representation for ILC. The cost is the additional mathematical machinery. The iteration dependency of the weighting matrices $Q$ and $R_{\weights}$ can be used to relax the dependency on the reference trajectory $\traj(t)$. As $Q$ and $R_{\weights}$ decrease in iteration-domain, the final desired state $\traj_{T}$ becomes more and more important.

% I should be able to estimate the gradient with much higher probability as I slow down. 
% so a dependence of gradient estimators with time T is needed as in
% Pr(update is descent direction) > 1 - exp(-\alpha T)

% Can we do projection analysis? Projection operator could do scalable learning by adapting T. Does this work with lifted vector representation?
% connect to path following/path manoueving literature
% null-space operator is also a projection operator. More precisely
% e = (I - F(F'F)^{-1}F')w where w = (d-s) are references + disturbances. In MIMO systems this projects it down to nullspace.

\bibliographystyle{plain}
%\bibliographystyle{./IEEEtran}
%\bibliography{./IEEEabrv,./iros2015Ref}
\bibliography{./tempRef}

\end{document}
