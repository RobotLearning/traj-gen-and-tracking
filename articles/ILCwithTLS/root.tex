% Temporarily as a separate document
% Will be placed inside the root latex file

\documentclass[10pt,a4paper]{article}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{color}
\usepackage{hyperref}

% theorem environment
\newtheorem{prop}{Proposition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{prop2}{Proposition}
\newtheorem{lem}{Lemma} 
\newtheorem{ex}{Example}

% For algorithms
\usepackage{algorithm}
\usepackage{algorithmic}

% custom commands
\newcommand{\boldvec}[1]{\boldsymbol{\mathrm{#1}}}
\let\vec\boldvec
\newcommand\at[2]{\left.#1\right|_{#2}} % the at differential sign
\newcommand\scalemath[2]{\scalebox{#1}{\mbox{\ensuremath{\displaystyle #2}}}} % scaling matrices
\DeclareMathOperator{\vect}{vec}

%% custom macros

% % % % Robot control terminology % % % %
\newcommand{\todo}{\textcolor{red}{TODO}} % TODO!
\newcommand{\kin}{\mathcal{T}} % used to denote inverse kinematics
\newcommand{\invKin}{\mathcal{T}^{-1}} % used to denote inverse kinematics

\newcommand{\joint}{\vec{q}} % used to denote robot state in joint space
\newcommand{\state}{\vec{x}} % denotes the generalized coordinates - joint space and velocity coordinates
\newcommand{\error}{\vec{e}} % difference between state and reference
\newcommand{\traj}{\vec{s}} % used to denote the points on the trajectory to be tracked

\newcommand{\dist}{\vec{\epsilon}} % denotes the disturbances acting on the rigid body dynamics
\newcommand{\linDist}{\vec{d}} % denotes the disturbances on the LTV model

\newcommand{\sysInput}{\vec{u}} % used to denote the system inputs
\newcommand{\linInput}{\tilde{\sysInput}} % denotes the LTV inputs
\newcommand{\trjInput}{\vec{\nu}} % denotes the inputs on the trajectory (calculated using IDM)
\newcommand{\ilcInput}{\sysInput_{\mathrm{ILC}}}

% % % % TLS terminology % % % %
\newcommand{\designMat}{\vec{X}} % design matrix
\newcommand{\latentMat}{\vec{Z}} % latent matrix
\newcommand{\observations}{\vec{y}} % observations vector
\newcommand{\param}{\vec{\beta}} % parameter vector
\newcommand{\residual}{\vec{r}} % residuals
\newcommand{\weightingMat}{\vec{W}} % weighting the residuals
\newcommand{\errorMat}{\vec{E}} % error matrix
\newcommand{\covarRes}{\vec{\Sigma}_{\residual}} % residual covariance
\newcommand{\leftEigenvector}{\vec{U}} % U of SVD
\newcommand{\rightEigenvector}{\vec{V}} % V of SVD

% % % % ILC terminology % % % %
\newcommand{\qmatrix}{\vec{\Gamma}} % denotes the filtering qmatrix term of Bristow et al.
\newcommand{\lmatrix}{\vec{L}} % denotes the learning matrix of Bristow et al.
\newcommand{\systemMat}{\vec{F}} % system matrix after linearization of f
\newcommand{\dynamics}{\vec{f}}
\newcommand{\dynamicsNominal}{\dynamics_{\mathrm{nom}}}
\newcommand{\policy}{\vec{\pi}}
\newcommand{\ValueFunction}{J}
\newcommand{\episode}{k} % used for episode number

\newcommand{\totalTime}{T} % total time duration 
\newcommand{\numSteps}{N} % total number of time steps
\newcommand{\numepisode}{K} % total number of episodes

\newcommand{\threshold}{\epsilon}
\newcommand{\alg}{\emph{tILC}}
\newcommand{\dataset}{E}

\newcommand\red[1]{{\color{red}#1}}
\newcommand\blue[1]{{\color{blue}#1}}
\newcommand\bluebold[1]{\textbf{{\color{blue}#1}}}
\newcommand\gray[1]{{\color{gray}#1}}

% Set the paths where all figures are taken from:
\graphicspath{{Pictures/}}
\mathtoolsset{showonlyrefs} 
\newcommand{\includesvg}[1]{%
% \executeiffilenewer{#1.svg}{#1.pdf}%
% {inkscape -z -D --file=#1.svg %
% --export-pdf=#1.pdf --export-latex}%
 \input{#1.pdf_tex}%
}

\author{Okan Ko\c c, Guilherme Maeda and Jan Peters}
\title{Cautious Learning Control with Total Least Squares}
\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

Iterative Learning Control is a control theoretic learning paradigm that aims to iteratively improve the tracking performance of a repetitive system. Optimization based approaches to ILC assume that a detailed knowledge of the plant to be controlled is available. However, such approaches can diverge terribly due to overconfidence. 

In this paper, we propose a more cautious ILC algorithm using total least squares (TLS), that is robust with respect to modeling uncertainties. Moreover we give a Bayesian interpretation of TLS and build an adaptive routine that can adaptively identify the underlying linearized model. Simulation and real robot results confirm the practical significance of our contributions. %incrementally or iteratively identify?
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Introduction}

% RC reference needed
Learning Control paradigms, and in particular Iterative Learning Control (ILC) \cite{Arimoto84}, \cite{Bristow06} and Repetitive Control (RC), aim to iteratively improve the tracking performance of a control system subject to repetitive tasks. In ILC, these tasks are episodic in nature: follow a desired trajectory for a fixed duration and repeat. In RC, the task is periodic but also continuous, and unlike ILC the system is not reset to a certain initial state. 

Methods that learn to track (periodic or episodic) trajectories need to compensate for modeling uncertainties and other repetitive disturbances acting on the system to be controlled. When all such disturbances are compensated for the system knowledge can be said to be indirectly acquired. However, stable methods that can efficiently and safely learn the dynamics are model-based (e.g. most of optimization-based ILC \cite{Amann95},\cite{Bristow06}) and at least require a global understanding of the dynamics of the system \cite{Kolter09}, \cite{NguyenTuong11}.

% refs needed
When executing model-based learning algorithms on dynamic systems, it is essential for stability and safety to incorporate a notion of model uncertainty. Otherwise the learning algorithms can be overconfident and easily go unstable~\cite{Longman2000}. One way to achieve a more stable performance is to use regularization. For example, in ILC, the inputs or the change in inputs applied to a system can be penalized. These robust methods in ILC are mostly known as Q-filtering~\cite{Bristow06} and typically incur a trade-off between stability and performance: system will often converge to a nonzero steady-state error. % if the learning algorithm is agnostic to the true dynamics of the system, it will fail to converge to zero steady-state error.

% is it the stability margin? or simply monotonic convergence?
In this paper, we introduce another way to increase the stability margins of model-based ILC algorithms that does not incur such a trade-off. We treat the modelling uncertainty issue in an errors-in-variables regression context and use Total Least Squares (TLS) to perform the ILC updates. This way we exercise caution and ensure robustness with respect to model uncertainty. % while at the same time improving the steady-state performance. 

Our contributions to Learning Control can be summarized as follows:

\begin{itemize}
\item We form a link between model-based Learning Control methods and errors-in-variables regression models, and analyze in particular Total Least Squares (TLS).
\item We prove that we increase the stability margins (in the iteration domain) of ILC by incorporating a truncated TLS update rule, and ensure monotonic convergence without sacrificing minimal steady-state error. 
% is it block Hankel or block lower triangular
\item We exploit the structure of the block lower triangular matrix estimation problem within TLS and increase its applicability for control problems. Simulation and real robot experimental results are presented.
\item We show as an extension of our ideas, one way to incorporate a Bayesian update rule within TLS and achieve self-tuning property. 
% relation to Kalman filter and other methods? Higher order ILC?
\end{itemize}

The outline of the paper is as follows: in the next subsection \ref{relatedWork} we give a brief literature review related to our work. In section \ref{methodology} we start by analyzing Total Least Squares. We present truncated structured TLS, along with pseudocode, and show its applicability in Iterative Learning Control. The resulting algorithm $\alg$ with minor modifications can be applied to Repetitive Control (RC) as well. In subsection \ref{ilcTLS} we prove the monotonic convergence and minimal steady state error of $\alg$. An adaptive version of $\alg$ is presented in \ref{adaptiveILC}, simulation results and real robot experiments are given in \ref{results}. Finally, conclusions and brief mention of possible future directions to explore are given in \ref{conclusions}.

% references required as always.  
\subsection{Related Work}\label{relatedWork}

A thorough investigation of the statistical properties of Total Least Squares (TLS) as well as its extensions such as structured TLS are presented in \cite{VanHuffel91}. For a short overview see \cite{Golub80} or the Appendix in \cite{Golub96}. Literature on TLS is huge and the application areas are growing rapidly. For some of the applications of TLS and errors-in-variables modelling, see the recent book \cite{VanHuffel13}. Truncated total least squares as a regularization method~\cite{Fierro97} is widely used in practice. % ref?
% relation to PCA? refs?

One of the first papers that introduced Iterative Learning Control (ILC) is \cite{Arimoto84}. For a good survey, see \cite{Bristow06} or \cite{Moore07}. Desirable properties of ILC algorithms include stability and monotonicity, and are discussed, for example, in \cite{Norrloef02} and \cite{Bristow06}. Optimization based ILC is described, for example, in \cite{Amann95}, \cite{Bristow06}, \cite{Moore07}. It seems we are not the first to notice the connection between ILC and TLS: another application of TLS in ILC using Tikhonov regularization~\cite{Golub99} is given in \cite{ZhangBo14}. In this work we use instead truncated total least squares (TTLS).

% % 2D systems analysis reference?
% % More applications of TLS? Especially in system identification, modelling, signal processing, etc.
% % Repetitive Control??
% % Shall we mention the ILC in nonlinear control systems review?

\section{Methodology}\label{methodology}

In this section we start by fixing the notation that we use for regression. We introduce more control-theoretic notation as we go along.
%
\subsection{Linear Least Squares}
Let $\designMat \in \mathbb{R}^{m \times n}$ be the design matrix, $\observations \in \mathbb{R}^{m}$ the vector of observations and  $\param \in \mathbb{R}^{n}$ the parameter vector to be estimated: $\designMat\param \approx \observations$. In this linear regression model $\residual = \observations - \designMat\param$ are the residuals that are to be minimized with respect to 2-norm~\cite{Golub80}
%
\begin{equation}
\begin{aligned}
\text{minimize} &\ \residual^{\mathrm{T}}\weightingMat\residual, \\
\text{subject to} &\ \observations + \residual \in \text{Range}(\designMat).
\end{aligned}
\label{lls}
\end{equation}
%
\noindent The positive definite weight matrix $\weightingMat$ is ideally the inverse of the covariance matrix $\covarRes$ of the residuals. The well-known \emph{normal equations} $\designMat^{\mathrm{T}}\weightingMat\designMat \param = \designMat^{\mathrm{T}} \weightingMat\observations$ is the unique closed-form solution to this problem in case $\designMat$ is of full rank, $\text{rank}(\designMat) = n$. Solution to the normal equations can then be computed in a numerically stable way~\cite{Golub96} using e.g. QR decomposition methods. If the design matrix $\designMat$ is of low rank, pseudoinverse $\designMat^{\dagger}$ finds out of infinitely many solutions the minimum 2-norm solution $\hat{\param}$ and can be computed using SVD. % this should be verified. [see Golub'96]

In case the design matrix $\designMat$ is numerically rank-deficient (i.e. its condition number is large), ridge regression (i.e. Tikhonov regularization) or truncation methods can be used to regularize (and hence to come up with a numerically stable estimate of) the parameter $\param$ in \eqref{lls}. Truncation can be applied conveniently with the pseudoinverse: invert the large singular values of $\designMat$ above a certain user-specified threshold $\threshold$ and truncate the rest to zero.

\subsection{Total Least Squares: an errors-in-variables model}
% shall we use multiple right hand sides?
% include weighting in the derivation?

Total Least Squares (TLS) is an errors-in-variables model that is applicable when the design matrix $\designMat$ is also not precisely known,
i.e. $(\designMat + \errorMat)\param = \observations + \residual$ for an unknown $\errorMat$ hopefully with small norm. A Frobenius-norm optimization procedure with diagonal weighting matrices $\weightingMat_{L} \in \mathbb{R}^{m \times m}$ and $\weightingMat_{R} \in \mathbb{R}^{n+1 \times n+1}$ is a natural extension of \ref{lls} under this model
%
\begin{equation}
\begin{aligned}
\text{minimize} &\ \| \weightingMat_{L} \begin{bmatrix} \errorMat & \residual \end{bmatrix} \weightingMat_{R} \|_{F}, \\
\text{subject to} &\ \observations + \residual \in \text{Range}(\designMat + \errorMat).
\end{aligned}
\label{tls}
\end{equation}
%
\noindent The singular-value decomposition (SVD) based solution to \eqref{tls} is described in \cite{Golub80} \footnote{However in general \ref{tls} fails to have a solution. An example with low-rank design matrix can be found in \cite{Golub80}} and relies on the Eckart-Young theorem. We show here for convenience the case where the weighting matrices $\weightingMat_{L}$ and $\weightingMat_{R}$ are identity. Rewriting $(\designMat + \errorMat)\param = \observations + \residual$ as  
%
\begin{equation}
\begin{aligned}
\begin{bmatrix} \designMat + \errorMat & \observations + \residual \end{bmatrix} \begin{bmatrix} \param \\ -1 \end{bmatrix} = 0, \\
\end{aligned}
\end{equation}
%
\noindent and using the Eckart-Young decomposition for a minimum Frobenius norm matrix $\begin{bmatrix} \hat{\errorMat} & \hat{\residual} \end{bmatrix}$% reference needed 
%

\begin{align}
\begin{bmatrix} \designMat & \observations \end{bmatrix} = \begin{bmatrix} \leftEigenvector_{\designMat} & u_{\observations} \end{bmatrix} \begin{bmatrix} \Sigma_{\designMat} & 0 \\ 0 & \sigma_{\observations} \end{bmatrix} \begin{bmatrix} \rightEigenvector_{\designMat \designMat} & \vec{v}_{\designMat \observations}, \\ \vec{v}_{\observations \designMat} & v_{\observations \observations} \end{bmatrix}^{\mathrm{T}}, \label{eckart1}\\
\begin{bmatrix} \designMat + \hat{\errorMat} & \observations + \hat{\residual} \end{bmatrix} = \begin{bmatrix} \leftEigenvector_{\designMat} & u_{\observations} \end{bmatrix} \begin{bmatrix} \Sigma_{\designMat} & 0 \\ 0 & 0 \end{bmatrix} \begin{bmatrix} \rightEigenvector_{\designMat \designMat} & \vec{v}_{\designMat \observations}, \\ \vec{v}_{\observations \designMat} & v_{\observations \observations} \end{bmatrix}^{\mathrm{T}} \label{eckart2}.
\end{align}
% 
\noindent After subtracting \eqref{eckart2} from \eqref{eckart1} and manipulating we get
%
\begin{align}
\hat{\param}_{tls} &= -\frac{V_{\designMat \observations}}{v_{\observations \observations}}, \label{tls1} \\
\hat{\errorMat} &= U_{\designMat} \Sigma_{\designMat} V_{\designMat \designMat}^{\mathrm{T}} - \designMat. \label{tls2}
\end{align}

\noindent See Figure~\ref{Figure1} for an illustration in one-dimensional regression. The case for multiple right-hand sides (i.e. $\observations \in \mathbb{R}^{n \times k}, k > 1$) and diagonal weighting matrices is given in \cite{Golub96}. Further extensions including partial, global, structured, and truncated TLS can be found in \cite{VanHuffel91}. 
% more citations are necessary!
% mention that we are extracting a latent dynamics matrix F_est = F + E!
Pseudocode for a general structured and truncated total least squares algorithm implementing an SVD solution is given in Algorithm~\ref{alg1}. The latent matrix estimation step is made explicit. % refer to latent matrix estimation (PCA?) literature.

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{LSvsTLS.jpg}%
\caption{Comparison between least squares and total least squares in the one dimensional estimation setting, taken from \cite{Golub80}. Least Squares minimizes the sum of the squared vertical distances from observations to the regression line. Total Least Squares is also known as orthogonal regression in 1D and minimizes instead the sum of the squared perpendicular distances.}
\label{Figure1}
\end{figure}
%

\begin{algorithm}[tb]
   \caption{Structured Truncated Total Least Squares}
   \label{alg1}
\begin{algorithmic}
   \STATE {\bfseries Input:} $\threshold > 0$, $\designMat$, $\observations$, 
   \STATE Compute SVD solution to $\begin{bmatrix} \designMat & \observations \end{bmatrix}$
   \STATE Estimate $\param$
   \STATE Estimate the latent matrix $\latentMat$ 
\end{algorithmic}
\end{algorithm}

%
\subsection{Iterative Learning Control with Total Least Squares}\label{ilcTLS}
%
In Iterative Learning Control (ILC) the goal is to drive deviations from a fixed reference trajectory $\traj(t), \ 0 \leq t \leq T \ $ in state space $\state \in S \subset \mathbb{R}^{p}$ to zero when the system to be controlled is subject to unknown repeating disturbances and model mismatch \cite{Bristow06}. As opposed to other adaptive (learning) control approaches, in ILC usually the feedforward control inputs to the system $\sysInput(t)$ are adjusted after each iteration $k$, or episode, is completed and the resulting deviations $\error(t) = \state(t) - \traj(t)$ from the desired trajectory are observed. % references to adaptive control literature?

Consider a general nonlinear dynamical system governed by the differential equation
%
\begin{align}
\dot{\state} &= \dynamics(\state,\sysInput), \label{dynamics} \\
\dot{\state} &= \dynamicsNominal(\state,\sysInput) + \dist(\state,\sysInput). \label{dynamicsNom}\\
\end{align}
%
% reference to other nonlinear approaches to ILC?
\noindent Assume that the nominal model $\dynamicsNominal$ is all we know about the system in \eqref{dynamics}. Nonlinear approaches to ILC mostly consider linearizations of \eqref{dynamicsNom} around the trajectory $\traj(t)$ and nominal inputs $\trjInput(t)$. Discretizing and stacking the linear time varying matrices obtained, we get the following \emph{lifted-form} approximation of the underlying dynamics
%
\begin{equation}
\begin{aligned}
\error \approx \systemMat \sysInput - \linDist.
\end{aligned}
\label{approxModel}
\end{equation}
%
\noindent Conventional ILC algorithms using such a linearized model compute at each iteration the feedforward compensation signals $\sysInput$ to drive error $\error$ to minimum achievable error (ideally zero). For example, the ILC algorithm utilizing stable plant inversion with truncated pseudoinverse computes the updates using % ref needed
% in MATLAB the command is pseudoinv(X,eps)
%
\begin{equation}
\begin{aligned}
\sysInput = \systemMat^{\dagger}\linDist. 
\end{aligned}
\label{pseudoinverseILC}
\end{equation}
% add the iteration varying formulation here also
%
However, the compensations \eqref{pseudoinverseILC} are computed using the approximate model in \eqref{approxModel} and should be taken with a grain of salt. In particular, for safety purposes one needs to consider the \emph{monotonic stability} of the ILC algorithm~\cite{Bristow06}. We take this into account by using truncated Total Least Squares to come up with a more cautious ILC update
%
\begin{equation}
\begin{aligned}
\sysInput_{TLS}, \ \errorMat &= \arg\min_{\sysInput,\errorMat} \|\begin{bmatrix}\errorMat & \residual \end{bmatrix} \|_{F}, \\
\residual &= \linDist - (\systemMat + \errorMat)\sysInput.
\end{aligned}
\end{equation}

%
\subsection{Adaptive ILC based on Bayesian TLS}\label{adaptiveILC}
%
% The prior weighting of the nominal model before starting the adaptive procedure can be based on the number of samples used in the identification of the block Hankel matrix F.

% Bayesian ILC is by definition a higher order ILC!

\section{Results}\label{results}

%
\subsection{Simulation Results of Seven DOF Barrett Arm}
%
In the simulation results shown below, ILC with pseudoinverse cannot approach trajectory very well, and after 8 iterations starts to diverge.
\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{beforeILC.eps}%
\includegraphics[width=0.5\textwidth]{afterILCPseudoInv.eps}		
\caption{Before and after applying ILC (10 iterations)}
\end{figure}
%
ILC with truncated total least squares on the other hand approaches the trajectory very well, and shows excellent tracking performance.
%
\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{beforeILC.eps}%
\includegraphics[width=0.5\textwidth]{afterILCTLS.eps}		
\caption{Before and after applying ILC (10 iterations)}
\end{figure}
%

\subsection{Applications in Robotic Table Tennis}

\section{Conclusions and Future Work}\label{conclusions}


\bibliographystyle{plain}
%\bibliographystyle{./IEEEtran}
%\bibliography{./IEEEabrv,./iros2015Ref}
\bibliography{./tempRef}

\end{document}
