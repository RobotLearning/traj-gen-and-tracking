\documentclass[letterpaper, 10 pt, conference]{ieeeconf}
%\documentclass[10pt,a4paper]{article}
\IEEEoverridecommandlockouts % This command is only needed if you want to use the \thanks command

\overrideIEEEmargins % Needed to meet printer requirements.

\usepackage[latin1]{inputenc}
\usepackage{amsmath}
%\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{color}
%\usepackage{hyperref}

% theorem environment
\newtheorem{prop}{Proposition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{prop2}{Proposition}
\newtheorem{lem}{Lemma}
\newtheorem{ex}{Example}

% For algorithms
\usepackage{algorithm}
\usepackage{algorithmic}

% custom commands
\newcommand{\boldvec}[1]{\boldsymbol{\mathrm{#1}}}
\let\vec\boldvec
\newcommand\at[2]{\left.#1\right|_{#2}} % the at differential sign
\newcommand\scalemath[2]{\scalebox{#1}{\mbox{\ensuremath{\displaystyle #2}}}} % scaling matrices

%% custom macros

% % % % % % % % Notation for robot % % % % % % %
\newcommand{\todo}{\textcolor{red}{TODO}} % TODO!
\newcommand{\kin}{\mathcal{K}} % used to denote forward kinematics
\newcommand{\invKin}{\mathcal{K}^{-1}} % used to denote inverse kinematics

\newcommand{\joint}{\vec{q}} % used to denote robot state in joint space
\newcommand{\state}{\vec{y}} % denotes the generalized coordinates - joint angles and angular velocities
\newcommand{\error}{\vec{e}} % difference between state and reference
\newcommand{\traj}{\vec{r}} % used to denote the points on the trajectory to be tracked

\newcommand{\dynamics}{\vec{f}}
\newcommand{\dynamicsNominal}{\dynamics_{\mathrm{nom}}}
\newcommand{\dist}{\vec{\epsilon}} % denotes the disturbances acting on the rigid body dynamics
\newcommand{\sysInput}{\vec{u}} % used to denote the system inputs
\newcommand{\trjInput}{\sysInput_{\mathrm{IDM}}} % denotes the inputs on the trajectory (calculated using IDM)

\newcommand{\policy}{\vec{\pi}}
\newcommand{\ValueFunction}{J}
\newcommand{\episode}{k} % used for episode number
\newcommand{\totalTime}{T} % total time duration 
\newcommand{\numSteps}{N} % total number of time steps
\newcommand{\threshold}{\epsilon}
\newcommand{\alg}{\emph{ptt}} % probabilistic table tennis
\newcommand{\dataset}{\mathcal{D}}

% % % % % % % % Table tennis notation % % % % % %
\newcommand{\ballFull}{\vec{x}_{B}} % ball cartesian state
\newcommand{\ball}{\vec{b}} % ball positions
\newcommand{\ballRadius}{r_B}
\newcommand{\ballVel}{v} 
\newcommand{\ballDynamics}{\vec{F}} % ball dynamics
\newcommand{\drag}{C} % drag
\newcommand{\gravity}{g}
\newcommand{\bounce}{\vec{E}} 
\newcommand{\contact}{\vec{C}} % contact model
\newcommand{\racket}{\vec{r}} % racket positions
\newcommand{\racketRadius}{r_R} % racket radius
\newcommand{\orient}{\vec{o}} % racket orientations
\newcommand{\normal}{\vec{n}} % racket normal
\newcommand{\robot}{\vec{x}_{R}} % racket state involving pos,vel and orient
\newcommand{\stabilityRegion}{\mathcal{S}} % stability region in ball phase space
\newcommand{\court}{\mathcal{T}} % opponents court
\newcommand{\net}{\mathcal{N}} % net
\newcommand{\wall}{\mathcal{W}} % wall

% % % % % % % % Probability notation % % % % % % %
\newcommand{\prob}{\mathbb{P}} % probability
\newcommand{\landTime}{\tau} % random variable
\newcommand{\landEvent}{\mathcal{L}} % land on table
\newcommand{\landDist}{p(\tau)} % distribution of landing time
\newcommand{\hitTime}{\nu} % hitting time
\newcommand{\hitEvent}{\mathcal{H}}
\newcommand{\hitDist}{p(\nu)} % distribution of hitting time
\newcommand{\KL}{D_{\mathrm{KL}}}


% Set the paths where all figures are taken from:
\graphicspath{{Pictures/}}
\mathtoolsset{showonlyrefs} 
\newcommand{\includesvg}[1]{%
% \executeiffilenewer{#1.svg}{#1.pdf}%
% {inkscape -z -D --file=#1.svg %
% --export-pdf=#1.pdf --export-latex}%
 \input{#1.pdf_tex}%
}

\author{Okan Ko\c c$^{1}$, Guilherme Maeda$^{2}$, Jan Peters$^{1,2}$% <-this % stops a space 
\\
{\tt\small \{okan.koc, jan.peters\}@tuebingen.mpg.de}%
\thanks{$^{1}$Max Planck Institute for Intelligent Systems,
        Spemannstr. 38, 72076 Tuebingen, Germany}
\thanks{$^{2}$Technische Universitaet Darmstadt, FG Intelligente Autonome Systeme
        Hochschulstr. 10, 64289 Darmstadt, Germany}
}
\title{A New Performance Criterion in Robotic Table Tennis}

\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

In highly dynamics tasks that involve moving targets, planning is necessary to figure out when, where and how to intercept the target. In robotic table tennis in particular, conventional planning algorithms often rely on the virtual hitting plane hypothesis to construct robot striking trajectories. These algorithms however are vulnerable to modeling and execution errors. %For example, the trajectories they generate are not robust to uncertainty in ball position and velocity at hitting time. 
Moreover, they do not take advantage of the inherent task redundancy when planning trajectories. In this paper, we address these two issues by introducing a new performance criterion for robotic table tennis. We use an optimal control approach to construct a novel inverse-kinematics algorithm that does not involve a fixed hitting plane. Furthermore, by augmenting our cost functional with a probabilistic final-cost we incorporate the uncertainties in modeling, estimation and execution as well as task redundancy. Our algorithm returns the balls with a higher probability to the opponents court in two and three dimensional table tennis with different robot models when compared with a state of the art planning approach. 

% better term for task redundancy?
% certainty-equivalent, cautious


\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\input{introduction}
%\input{method}
%\input{experiments}
%\input{conclusion}

\section{INTRODUCTION}

The opponent's court in table tennis, the net and other environmental restrictions such as walls together define a natural \emph{stability region} that is intrinsic to the game: the table tennis playing robot implementing our favorite reinforcement learning and control algorithm will lose a point if they cannot land the ball on the other side of the table. Taken in a wider sense, this stability region is a result of the redundancy in task-specification, and should be exploited as much as possible in all robotic tasks. 
% $\court$

An aspect in table tennis that strengthens this point is the uncertainty in ball estimation. As a result of limitations in the sensing hardware as well as in our simple physical models that neglect certain dynamics, the ball cannot be estimated or predicted perfectly within the workspace of the robot. In an ideal world where this could be done, exploitation of task-redundancy could indeed be relegated to a higher-level strategy, as is often done in previous works in table tennis~\cite{Muelling13}. However, whenever there is ball uncertainty, being aware and taking advantage of the stability region is critical and directly contributes to generating successful playing styles.
%  It is difficult to estimate the center of mass of the ball from image data. Small errors in position can accumulate to much larger errors in velocity estimates. Moreover, the ball is very light and some effects such as spin cannot be predicted precisely even with sophisticated modelling.

% But nobody should blame them if they land the ball precisely on a target point but only within a certain region of it: they do not have to! Even humans with very agile striking capabilities are not able to return the ball to a precise location.
% mention human studies in this aspect

In this paper, we incorporate probabilistic modeling for robust trajectory generation and come up with a new performance criterion in table tennis that exploits the game's natural stability criterion. The cost functional that we try to minimize is not \emph{certainty-equivalent} and naturally leads to \emph{cautious} strategies. Moreover it is particularly suitable for employing adaptive strategies as the robot gets more data and refines its internal models of the environment. 

Our approach involves intensive modeling of task-relevant quantities from data, e.g. ball flight, bounce models and ball-racket contact modeling. The last one especially can be hard to train from missing data. However, we keep the uncertainty of all of our models and use them also in our decision-making process. This cautious design is an asset that differentiates our approach from previous approaches (e.g. \cite{Matsushima05}, \cite{Muelling13}) that are less robust to modeling and estimation uncertainty.
% from missing data and can even be misleading when given example ball trajectories with high spin.

To summarize our reasons for introducing uncertainty and probabilistic modeling to trajectory generation in table tennis: \textit{i)} Table tennis balls are very light and cannot be estimated or predicted precisely. \textit{ii)} Racket-ball interaction is generally not known well and the elasticity of the momentum exchange differentiates it from the mirror laws used in the literature so far. \textit{iii)} The set of allowed landing point specifications in the opponent's side can be incorporated to design robust algorithms that return the ball with a higher probability, when under the influence of various effects mentioned in \textit{(i)} and \textit{(ii)}. See Figure~\ref{mainIdea} for an illustration.% ref needed obviously 
% velocity dependent coefficient of restitution

% The choice of the the desired landing point of the ball on the opponent's court is generally left to a higher level strategy or policy of the robot. However in this paper we argue that landing the ball successfully on the opponent's court is the \emph{fundamental goal} in table tennis. Therefore policies or the strategies involved in striking movement generation should be combined in one unitary whole.

\begin{figure}[t!]
\center
\includegraphics[scale=0.4]{robot1.png}			
\caption{Robotic table tennis setup with four cameras tracking the ball at 60 Hz. In order to return the ball to the opponent's court, we need to consider the uncertainty in ball estimation as well as in our ball-racket contact model. Introducing uncertainty into planning and a more cautious generation of striking trajectories will allow us to return the ball with a higher probability.}
\label{robot}
\end{figure}
% REPLACE PHOTO WITH ANOTHER ONE INCLUDING CAMERAS

In the rest of this paper, we elaborate on this notion of robustness, giving more examples and the necessary intuition where needed. In Section~\ref{relatedWork} we introduce previous work on table tennis and other relevant trajectory generation frameworks. In Section~\ref{method} we formalize robot trajectory generation as a specific optimal control problem and incorporate probabilistic modeling within this framework. We do not know of any closed-form solutions even in simplified cases. In Section~\ref{alg} we discuss a Monte-Carlo based rejection sampling approach for optimizing the previously introduced cost functional. In Section~\ref{results} we evaluate the performance of this approach and compare it with previous inverse kinematics (IK) approaches. When the inverse dynamics models are not known well for the robot, robustness with respect to trajectory \emph{execution} must be additionally considered. In the final section~\ref{end} we discuss several promising extensions in this regard. %VHP-based

\begin{figure}[t!]
\centering
\includegraphics[scale=0.4]{drawing.eps}			
\caption{Illustrating the main idea behind this paper: from the ball's point of view, a racket trajectory in table tennis has a certain probability of hitting the ball and a significantly smaller probability of landing it (legally) on the opponents court. From the racket's point of view, the ball motion is a certain stochastic process and it should be intercepted such that the marginal probability distribution at hitting time is transformed at landing time to a desired marginal distribution. Racket trajectory and the mean of the ball trajectory are shown in black and red, respectively. }
\label{mainIdea}
\end{figure}

\section{RELATED WORK}\label{relatedWork}

% this doesn't fit here so well
We will summarize the Virtual Hitting Point (VHP) framework here only very briefly. In this approach, the trajectory of the incoming ball is estimated and filtered from a stream of ball position estimates. Usually a physical flight model is used to predict the intersection point of the ball trajectory with a comfortably chosen VHP. For safety reasons, a minimum hitting time $T_{\textrm{min}}$ is also specified in addition to the coordinates of the hitting plane. When the ball is coming very fast towards the VHP, any calculated robot trajectory of duration below the minimum time will simply not be executed. The estimation process is terminated at least $T_{\textrm{min}}$ before the expected hitting time, to give the robot enough reaction time. This prevents high accelerations and any risk of damage to the robot. For more details see \cite{Muelling13}, or \cite{Matsushima05} for a more general discussion. 
%after a bounce event has been detected with high probability. 

% % % % Striking Movement Generation in Humans % % % % %
% speed-accuracy trade-off [Woodworth 1899, Fitts 1954]
% variability [Todorov and Jordan, 2002]
% goal-directed corrections [Elliott et al.]
% biomechanical redundancy [Bernstein, 1967]
% cost functions from optimal control [ Bryson and Ho, 1975; Hogan, 1984; Harris and Wolpert, 1998; Todorov and Jordan, 2002]
% motor program [Henry and Rogers, 1960; Keele, 19658; Schmidt, 1975; Schmidt and Wrisber, 2000, Schmidt, 2003]
% related: operational timing hypothesis [Tyldesley and Whiting, 1975]
% tau hypothesis to account for the time-to-contact: tau is specified as the relative inverse rate of dilation of the object image [Lee and Young, 1985; evidence for it: Bootsma and van Wieringen, 1988]
% stroke timing independent of ball speed [Hubbard and Seng, 1954] 
% error tolerance [Dagmar Sternad, Hermann Mueller, 2011]
% funnel-like control with fixed spatio-temporal bandwidth [Bootsma and Peper, 1992; Williams and Starkes, 2002]

% % % % Cost functions for movement generation % % % %
% cost of the movement includes - jerk, (metabolic) energy [Bryson and Ho, 1975]
% relationships found in reaching and pointing movements do not hold in striking sports [Bootsma and van Wieringen, 1990]
% energy optimality [Alexander, 1997; Kuo, 2005]
% Comfort of the posture, i.e. cost is induced by proximity to a fixed comfort posture in joint-space. 
% We believe that a new performance criterion in robotic table tennis is needed to explain the robust trajectory generation frequently observed in humans, and in order to compete with them. 

% robust movement generation
% robust algorithms that can compensate for low quality hardware and uncertainty in ball estimation

% hitting stage lasts approximately 80 ms in expert humans [only find a robust hitting trajectory]

% make sure to cite Marco Campi's scenario approach in robust control
% cite Stochastic Minimum Principle papers

% cite Yanlong's paper

\section{METHOD}\label{method}

In table tennis, one needs to specify when, where and how to intercept the incoming ball trajectory. After a successful hit however, the landing point of the ball is not completely specified. This \emph{task redundancy} in table tennis can be captured more formally, from a ball dynamics point of view, as a stability region $\stabilityRegion$ in phase space. As a set of desired ball positions and velocities, the geometry of $\stabilityRegion$ is approximately affine
%
\begin{align}
(\ball,\dot{\ball}) \in \stabilityRegion \subset \court \times \mathbb{R}^{3} \subset \mathbb{R}^{6},
\label{stabilityRegion}
\end{align}
%
\noindent where $\court$ is the set of Cartesian coordinates of the table $\court$, i.e. a rectangular region with a fixed vertical distance $z_{\court}$ from origin. The net and any other environmental constraints such as walls are the environmental factors constraining the set of desired ball velocities and will for simplicity of presentation be neglected. Any algorithm that can return the ball to this fixed region $\stabilityRegion \approx \court \times \mathbb{R}^3$ in phase space can be said to be \emph{stable}.
% it reduces approximately to
%
So far, most of the algorithms for robotic table tennis \cite{Matsushima05}, \cite{Muelling13} calculate the intersection point of an estimated ball trajectory with a Virtual Hitting Plane (VHP) to determine the space and time coordinates of the hitting point. They neglect to account for uncertainty in ball estimation or the underspecification of the task. Moreover the determination of a hitting time can be arbitrary, and the algorithms involving a VHP can lead to unnecessarily restrictive strokes. 
% do we really need a fixed event such as bounce to terminate the estimation process?
%It is possible to eliminate this termination event altogether and vary the robot trajectory launch times based on ball estimates.

% impact time, ball position and velocity
% time to contact

% or a similar event such as passing over the net

\subsection{Learning Models From Data}

% air resistance scale factor C 
% $\ballFull = (\ball^{\mathrm{T}},\dot{\ball^{\mathrm{T}}})^{\mathrm{T}}$
In this framework, we require three models for the trajectory generation process and acquire them (iteratively) from raw ball data. The ballistic \emph{flight model} is a nonlinear model $\ddot{\ball} = \ballDynamics(\dot{\ball})$ that describes the dynamics of the ball $\ball = (b_x,b_y,b_z)^{\mathrm{T}}$. It involves air drag $\drag$ and gravity $\gravity$
%
\begin{align}
\ddot{\begin{bmatrix}
   b_x \\
   b_y \\
   b_z   
 \end{bmatrix}} &= 
 \begin{bmatrix}
 -\drag \ballVel \dot{b}_x  \\
 -\drag \ballVel \dot{b}_y  \\
 \ \gravity - \drag \ballVel \dot{b}_z 
 \end{bmatrix},
\label{flightModel}
\end{align}
%
\noindent where $\ballVel = \|\dot{\ball}\|_2$ is the velocity of the ball. We use a linear model for the \emph{rebound model}
%
\begin{align}
\dot{\ball}_{\mathrm{out}} = \bounce\dot{\ball}_{\mathrm{in}}.
\label{reboundModel}
\end{align}

\noindent The rebound model \eqref{reboundModel} is a discrete event which reflects the ball when the ball with radius $\ballRadius$ is touching the table, i.e. the landing event
%
\begin{align}
\landEvent = \{b_z(t) = z_{\court} + \ballRadius \cap \dot{b}_z(t) < 0\},
\label{landingEvent}
\end{align}
%
%
\noindent occurs. Matrix $\bounce$ in \eqref{reboundModel} is a diagonal matrix with entries $\vec{\epsilon} = [\epsilon_{x}, \epsilon_{y}, -\epsilon_{z}]^{\mathrm{T}} \in (0,1)^{3}$. The coefficient of restitution $\epsilon_{z}$ accounts for the reflection of velocity in the vertical direction $z$ and $\epsilon_{x}, \epsilon_{y}$ are the coefficients of friction along the planar $x,y$ directions.
% incoming ball trajectory: as Gaussians indexed with time [e.g. Kalman filter should give us this information with prediction. Parameters/model of a Kalman filter could be fit using ball data (when fitting, innovation of the KF should be minimized as to consist mostly of white noise)]

% A probabilistic model describing the interaction model: outputs a probability distribution of outgoing ball states parameterized (or indexed) by t, e.g. b_t \approx N(\mu_b_out(t), \sigma_b_out(t))

% build a forward/inverse interaction model probabilistically
The last model to train from data is the \emph{ball-racket contact model} 
%
\begin{align}
\dot{\ball}_{\mathrm{out}} &= \contact(\dot{\ball}_{\mathrm{in}},\dot{\racket},\orient).
\label{ballRacketContactModel}
\end{align}
%
\noindent This model is significantly harder to train from the previous models, as it requires ball-racket interaction data and it is difficult to get reliable ball estimates around hitting time. We rely instead on Kalman smoothing using the trained flight model to estimate the ball velocities before and after hitting. In previous works, the outgoing velocity of the ball is calculated using a \emph{mirror law}: $o_{n} - v_{n} = -\epsilon_{R} (i_{n} - v_{n})$ with $v_{n}$ the speed of the racket along its normal and $\epsilon_{R} \in (0,1)$ the coefficient of restitution of the racket. Scalars $o_{n}$ and $i_{n}$ are the outgoing and incoming ball speeds along the racket normal, respectively. This model assumes an elastic momentum exchange and it is quite inaccurate, especially at high ball velocities.
% show that it is quite inaccurate with data
% is this true? is the parallel o and i definitions correct?

The accuracy of the models \eqref{flightModel} - \eqref{ballRacketContactModel} all depend on each other and for this reason, we train the parameters of these models with the smoothing Expectation-Maximization (EM) algorithm. Effects of angular velocity, or in other words spin, are not accounted for in these models.
% smoothing EM ref needed

\subsection{Predicting with Probabilistic Modeling}
 
During test time when running the trained models \eqref{flightModel} - \eqref{ballRacketContactModel} online, we use an Extended Kalman Filter (EKF) to perform prediction as well as filtering. Any other regression method to estimate initial ball position and velocity can also be used.
% density or distribution
Using an EKF for our nonlinear model \eqref{flightModel} generates at each time instant $t$ a probability distribution $p_t(\ball,\dot{\ball}|t)$ of incoming ball states parameterized by time, 
%
\begin{align}
\ball_t &\sim \mathcal{N}(\vec{\mu}_{\textrm{in}}(t),\vec{\Sigma}_{\textrm{in}}(t)). 
\end{align}
%
% % % EXT. KALMAN FILTER EQUATIONS HERE % % %
%
\noindent Formally this is a stochastic process, and for the Kalman Filter with a noisy process model, a Brownian motion. However we set the process covariance to zero during prediction, as the sample paths of the exponential kernel used in the Kalman Filter framework are very rough, i.e. almost surely not differentiable.

% Interaction probabilities (ball touching the racket)
Prediction continues after a possible interaction with the racket trajectory. If the ball touches the racket, i.e. if the surface of the ball is located inside the radius $\racketRadius = 8$ cm of the racket plane, ball incoming velocities will be transformed according to the trained contact model \eqref{ballRacketContactModel}. Otherwise the ball with continue its previous projectile-like motion following \eqref{flightModel}. Prediction is stopped at landing time $\landTime$ when the ball hits the table plane with negative velocity in the $z$ direction: 
%
\begin{align}
\landTime = \inf(t \geq 0 | b_z(t) = z_{\court} + \ballRadius \cap \dot{b}_z(t) < 0).
\label{landTime}
\end{align}
%
\subsection{Optimal Control for Trajectory Generation}

From a set point of view, for every point on the predicted ball trajectory, there is a range of admissible outgoing ball velocities that the racket can impart. This set is constricted by the stability region $\stabilityRegion$. 
%the geometry of the table and the demands of the game: the ball has to avoid the net and the walls and should land on the opponents court.
Putting a probability measure $\mu(\stabilityRegion)$ on this set is straightforward. For instance, the desired landing point distribution could be any distribution with compact support over the table. A uniform distribution $b_x, b_y \sim \mathcal{U}(\court) = \mathcal{U}(x_{a},x_{b})\mathcal{U}(y_{a},y_{b})$ or a truncated normal distribution are options that could be chosen as strategy demands. The limiting values $x_{a},x_{b},y_{a},y_{b}$ are obtained from the rectangular geometry of the opponent's court.
%

Our optimization criterion of choice is to find the racket trajectory that minimizes the Kullback-Leibler (KL) divergence $\KL(p\|q) = \int_{\court}p(x,y)\log(\frac{p(x,y)}{q(x,y)})\textrm{d}x\textrm{d}y$ of 
%
\begin{align}
p(b_x,b_y|\landEvent) = \int_{\landTime = 0}^{\infty} p_{\landTime}(b_x,b_y|\landEvent,\landTime)\landDist \textrm{d}\landTime
\label{marginalProcess}
\end{align}
%
from the uniform distribution $q(b_x,b_y|\landEvent) = \mathcal{U}(\court)$. The distribution $p(b_x,b_y|\landEvent)$ is the marginal distribution over time of the ball process $p_t(\cdot)$ conditioned on the landing event $\landEvent$. Here $\landTime$ is the \emph{hitting time} as in \eqref{landTime}, a random variable with distribution $p(\landTime)$ corresponding to the event $\landEvent$ in \eqref{landingEvent}.

% what about maximizing the probability of landing, regardless of any specified distribution?
% is this true?
Any specified distribution $q(\cdot)$ of compact support $\court$ will indirectly maximize the probability of landing on the table, $\prob(\landEvent) = \int_{0}^{\infty}\landDist\textrm{d}\landTime$. In addition, for maximal unpredictability, the robot player can choose the uniform distribution over the table as a desired distribution. In this case the optimization reduces to maximizing the entropy of the landing distribution on the table. 

Other more agnostic optimization criteria could also be formulated to minimize the racket trajectory sensitivity to perturbations in the ball trajectory. However these would not take advantage of the uncertainty quantification of the ball trajectory, in our case supplied by EKF.

For safety and efficiency, we would prefer trajectories with minimal acceleration or jerk, the derivative of acceleration. Combining the corresponding cost functional with the KL-divergence we get the following \emph{free-time} optimal control problem
%
\begin{align}
\min_{\sysInput,T} & \int\limits_{0}^{T}\sysInput(t)^{\mathrm{T}}\vec{R}\sysInput(t) + \KL(p(b_x,b_y|\landEvent)|\mathcal{U}(\court)), \\
& \textrm{s.t. } \ddot{\joint}(t) = \sysInput(t),
\label{costFnc1}
\end{align}
%
\noindent where the final time $T$ of the racket trajectory 
%
\begin{align}
\big(\racket(t),\orient(t)\big) &= \kin(\joint(t)),
\end{align}
%
\noindent is an additional variable to be optimized. $\vec{R} \succeq 0$ is a positive definite matrix. The conditional of the stochastic process $p_{\landTime}(b_x,b_y|\landEvent,\landTime)$ in \eqref{marginalProcess} can be expanded as follows
%
% should we give also the probability of landing here?
\begin{align}
p_{\landTime}(b_x,b_y|\landEvent,\landTime) &= \frac{ \int_{\dot{b}_z=-\infty}^{0}\int_{\dot{b}_x,\dot{b}_y}p_{\landTime}(b_x,b_y,z_{\court},\dot{\ball}|\landTime)\mathrm{d}\dot{\ball}}{\prob(\landEvent)}.
\label{marginalDistr2}
\end{align}
%
\noindent Finally we can relate the integrand $p_{\landTime}(b_x,b_y,z_{\court},\dot{\ball}|\landTime)$ to the racket trajectory by marginalizing over the outgoing ball state $\big(\ball_{\textrm{out}},\dot{\ball}_{\textrm{out}})$
%
%& p_{\landTime}(b_x,b_y,z_{\court},\dot{\ball}|\landTime) = 
\begin{align}
\int_{\ball_{\textrm{out}},\dot{\ball}_{\textrm{out}}}  p_{\landTime}(b_x,b_y,z_{\court},\dot{\ball}|\ball_{\textrm{out}},\dot{\ball}_{\textrm{out}},\landTime) p(\ball_{\textrm{out}},\dot{\ball}_{\textrm{out}})\textrm{d}\ball_{\textrm{out}}\textrm{d}\dot{\ball}_{\textrm{out}},
\label{fullDistrMarginal1}
\end{align}
%
\noindent where $p(\ball_{\textrm{out}},\dot{\ball}_{\textrm{out}})$ can be calculated using the trained models \eqref{flightModel} - \eqref{ballRacketContactModel}
%
\begin{align}
&\int_{0}^{T}\!\int_{\ball_{\textrm{in}},\dot{\ball}_{\textrm{in}}}\!p(\dot{\ball}_{\textrm{out}}|\dot{\ball}_{\textrm{in}},\dot{\racket}(\hitTime),\orient(\hitTime),\hitTime) p(\ball_{\textrm{out}}|\ball_{\textrm{in}},\racket(\hitTime),\orient(\hitTime),\hitTime)\textrm{d}\hitTime. %\hitDist
\label{fullDistrMarginal2}
\end{align}
% % % WORK ON THIS!!!
%
\noindent Here $\hitTime$ is the hitting time random variable corresponding to the time of ball-racket contact, i.e. 
%
\begin{align}
\hitTime = \inf\big(t \geq 0 | \ball(t) = \racket(t) + \gamma \orient_{\perp}(t), \gamma < \racketRadius, \orient_{\perp}(t) \perp \normal(t)).
\label{hitTime}
\end{align}
%$\prob(\hitEvent) = \int_{0}^{T}\hitDist\textrm{d}\hitTime$. 
%
By formulating \eqref{costFnc1} in joint space, we find the joint trajectory $\joint(t)$ that provides a suitable trade-off between minimum joint accelerations $\ddot{\joint}(t)$ and the KL-divergence. 

% Output
% 
% The mapping r_t \approx N(\mu_racket_center(t),\sigma_racket_center(t))) as racket reference trajectory that maximizes the probability of landing on the opponents court, or minimizing KL-divergence between outgoing ball states distribution and admissable/desired velocities [e.g. uniform distribution of velocities]

% Control: imposing transversality conditions when ball is on a curve p_b(t) or a set with some measure p_b [constant hamiltonian on this set?] we get a probability distribution of admissable end effector configurations
%
%
% Probability of interaction occurring: b(t) for the ball must lie in r(t) + \gamma o_\parallel(t), where r(t) is the racket centre trajectory, \gamma is less than the radius of the racket, and o_\parallel(t) is any direction perpendicular to the normal (i.e. orientation) of the racket.
%

% Refer to article for the simplest case when diving two Gaussians with nonzero mean.
The equations \eqref{costFnc1}, \eqref{fullDistrMarginal1} and \eqref{fullDistrMarginal2} are functions of the racket trajectory. When optimizing for \eqref{costFnc1} we do not know of any way to compute the gradient of the KL-divergence with respect to the racket trajectory in closed form. However, the outgoing ball trajectory is an integral over the previous incoming ball distribution using the ball-racket contact model. Any sampling based approach (e.g. rejection sampling) may be used to simulate then the outgoing ball trajectory and approximate the resulting landing distribution. 


\section{ALGORITHM}\label{alg}

\section{EXPERIMENTS}\label{results}

% % % CHANGE THE WRITING HERE !!! OTHERWISE ITS THE SAME AS PREVIOUS ARTICLE

% % % % Table Tennis Setup % % % %
For the robotic table tennis task we are using a seven degree of freedom (DoF) torque-controlled custom made Barrett WAM arm capable of high speeds and accelerations. A standard size racket (16 cm diameter) is mounted on the end-effector of the arm as can be seen in Figure~\ref{robot}. A vision system consisting of four cameras hanging from the ceiling around each corner of the table is used for tracking the ball \cite{Lampert12}. The orange ball is tracked visually with a sampling rate of 60 Hz and filtered with an EKF that accounts for some of the bouncing behavior of the ball and air drag effects. The table and the tennis balls are in accordance with the International Table Tennis Federation (ITTF) rules.
%
A ball launcher (see Figure~\ref{robot}) is available to throw balls accurately to a fixed position in Cartesian space to the forehand of the robot. The incoming ball arrives with low-variability in desired positions and higher-variability in ball velocities. The whole area to be covered amounts to about 1 m$^2$ circular region surrounding the initial forehand posture of the robot. This allows us to avoid the singularities of the robot. Any ball that appears outside of this circular \emph{feasible} region will not be hit.
%
After the visual system predicts a ball trajectory that coincides with the feasible region in Cartesian space, the motion planning system has to come up with a trajectory that specifies how, where and when to intercept the incoming ball. 
%Desired Cartesian position, velocity and orientations of the racket translate in joint space to a specification of 14 parameters: 7 joint angles and 7 joint velocities of the robot arm. Along with the desired hitting time (or the time until impact), these 15 parameters are used to train 7 joint space trajectories that correspond to the desired reference trajectory in Cartesian space.
%
In runtime, in order to generate feasible reference trajectories that account for the variations in incoming ball position and velocities, we run the robust trajectory generation framework $\alg$. We start these joint reference trajectories from the initial posture of the robot provided by the sensors.
% From Katharina's paper:
%the position, velocity and orientation of the racket can be computed analytically based on the state of the system and the target on the opponents court.
%These task space parameters can also be converted into joint space parameters using inverse kinematics

Due to the limitations of our setup, our robot is fixed to the ceiling. Hence we expect that the balls that hit the frontal areas of the robots table will not be hit. The table can be brought closer to the robot to overcome this limitation: however then the trajectory generation problem will be subsequently harder, and the hard constraint of hitting the table becomes more problematic to avoid.

% vision system operates in a semi-structured and human-inhabited environment
% Finite State Automaton: four stages: awaiting stage, preparation, hitting and finishing stage

\section{CONCLUSION}\label{end}

% stochastic optimal control
We see the probabilistic extensions of the Pontryagin's minimum principle \cite{Liberzon11} and stochastic optimal control in general, as a very fruitful direction for robotics in general in the upcoming years as robots start taking decisions in complex dynamic tasks. The robot trajectories in \eqref{fullDistrMarginal2} to be generated can also taken to be probabilistic, leading to an optimization framework that considers the interaction between two probability distributions. We consider the probabilistic movement primitives~\cite{Paraschos13} to be a step in this direction.

% reinforcement learning to modify trajectories

% shall we put inv. dynamics eq here?
The cost functional to be minimized considers the accelerations as the quantity to be minimized. It assumes that the feedback linearization of the robot is perfect, that is the inverse dynamics model for the robot is exact. Whenever the cancellation is imperfect due to inaccurate robot control, execution error will prevent the robot from achieving the desired trajectories. Execution errors are not taken into consideration within this framework. 

A natural reward signal to use for reinforcement learning is to look at the set-distance of the landing point from the opponents court
%
\begin{align}
d(\ball(\landTime),\court) = \inf_{\ball_z = z_{\court} + \ballRadius, \vec{x} \in \court} d(\ball,\vec{x}).
\end{align}
%
\noindent This negative reward can be used to modify the generated trajectories and learn to compensate for the execution errors. Another promising approach is Iterative Learning Control (ILC), see for example \cite{Bristow06}, \cite{Longman2000}, \cite{Koc15}. ILC is a more efficient learning approach that generally makes more assumptions. Generalizing ILC to different trajectories generated by $\alg$, we hope to compensate for any execution error and increase the performance of our robot further. 

\bibliographystyle{plain}
%\bibliographystyle{./IEEEtran}
%\bibliography{./IEEEabrv,./iros2015Ref}
\bibliography{./ttRef}

\end{document}
