% Temporarily as a seperate document
% Will be placed inside the IROS root latex file

\documentclass[10pt,a4paper]{article}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{color}

% custom commands
\newcommand\at[2]{\left.#1\right|_{#2}} % the at differential sign
\newcommand\scalemath[2]{\scalebox{#1}{\mbox{\ensuremath{\displaystyle #2}}}} % scaling matrices

%% custom macros
\newcommand{\todo}{\textcolor{red}{TODO}} % TODO!
\newcommand{\kin}{\mathcal{T}} % used to denote inverse kinematics
\newcommand{\invKin}{\mathcal{T}^{-1}} % used to denote inverse kinematics

\newcommand{\joint}{q} % used to denote robot state in joint space
\newcommand{\state}{\bar{\joint}} % denotes the generalized coordinates - joint space and velocity coordinates
\newcommand{\dmp}{s} % used to denote the dmp trajectory states
\newcommand{\error}{e} % difference between state and reference
\newcommand{\traj}{r} % used to denote the points on the trajectory to be tracked

\newcommand{\dist}{\epsilon} % denotes the disturbances acting on the rigid body dynamics
\newcommand{\linDist}{d} % denotes the disturbances on the LTV model

\newcommand{\sysInput}{u} % used to denote the system inputs
\newcommand{\linInput}{\tilde{u}} % denotes the LTV inputs
\newcommand{\trjInput}{\nu} % denotes the inputs on the trajectory


% % % % DMP terminology % % % %
\newcommand{\fullvec}{\psi} % full vector for state-ref-dmp-goal
\newcommand{\force}{f} % forcing term of the dmps
\newcommand{\phase}{x} % phase of the dmp
\newcommand{\weights}{w} % weights of the dmp
\newcommand{\basis}{\Phi} % basis functions of the dmp as a matrix

% % % % ILC terminology % % % %
\newcommand{\qmatrix}{\Gamma} % denotes the filtering qmatrix term of Bristow et al.
\newcommand{\lmatrix}{L} % denotes the learning matrix of Bristow et al.

\newcommand{\observations}{\mathbf{y}} % used for the observed output
\newcommand{\dynamics}{f}
\newcommand{\dynamicsNominal}{f_{\mathrm{nom}}}
\newcommand{\policy}{\mathbf{\pi}}
\newcommand{\ValueFunction}{J}
\newcommand{\episode}{k} % used for episode number

\newcommand{\totalTime}{T} % total time duration 
\newcommand{\numSteps}{N} % total number of time steps
\newcommand{\numepisode}{K} % total number of episodes

\newcommand{\threshold}{\epsilon_s}
\newcommand{\alg}{\emph{wILC}}
\newcommand{\dataset}{E}

\author{Okan Ko\c c}
\title{Optimal Striking Movement Generation \& Representation}
\begin{document}
\maketitle

\section{Introduction}

\section{Related Work}

\section{Problem Statement}

\subsection{ILC Review}

In this section we will first review some of the results from the Iterative Learning Control (ILC) literature \cite{Bristow06}. Consider the nonlinear robot dynamics of the form:

\begin{equation}
\begin{aligned}
\ddot{\joint} &= \dynamics(\joint,\dot{\joint},\sysInput) + \dist(\joint,\dot{\joint})\\
\ddot{\joint} &= M^{-1}(\joint)\{ \tau(\sysInput) - C(\joint,\dot{\joint})\dot{\joint} - G(\joint)\} + \dist(\joint,\dot{\joint})\\
\end{aligned}
\label{dynamics}
\end{equation}

where on the right hand side are the terms due to the rigid body dynamics model and $\dist(\joint,\dot{\joint})$ are the (unmodeled) disturbances that act on the robot, such as viscous friction, stiction, etc. This system can be linearized around a given joint space trajectory $\traj(t), \ 0 \leq t \leq T$ with nominal inputs $\nu(t)$ to obtain the following linear time varying (LTV) representation:

\begin{equation}
\begin{aligned}
\dot{\error} = A(t)\error(t) + B(t)\linInput(t) + \linDist(t,\sysInput)
\end{aligned}
\label{LTV}
\end{equation}

where $\error(t) = \state(t) - \traj(t)$, $\state = [\joint,\dot{\joint}]^{\mathrm{T}}$, $\linInput(t) = \sysInput(t) - \trjInput(t)$ and the time varying matrices are:

\begin{equation}
\begin{aligned}
A(t) &= \at{\frac{\partial{\dynamics}}{\partial{\state}}}{(\traj(t),\trjInput(t))} \\
B(t) &= \at{\frac{\partial{\dynamics}}{\partial{\sysInput}}}{(\traj(t),\trjInput(t))}
\end{aligned}
\label{LTVmatrices}
\end{equation}

Here the additional term $\linDist(t,\sysInput)$ are due to the disturbances and the effects of the linearization. We can discretize (\ref{LTV}-\ref{LTVmatrices}) with step size $\Delta t$, $N = T/\Delta$ and step index $j = 1, \ldots, N$ to get the following discrete linear system:

\begin{equation}
\begin{aligned}
\error(j+1) = A^{D}(j)\error(j) + B^{D}(j)\linInput(j) + \linDist(j, \sysInput(1), \ldots, \sysInput(j))
\end{aligned}
\label{discreteLTV}
\end{equation}

Here $A^D$ and $B^D$ are the discretizations of \eqref{LTVmatrices} can be calculated using the trick \cite{Schoellig12}:

\begin{equation}
\begin{aligned}
\exp^{h
\left[
\scalemath{0.5}{
\begin{array}{c|c}
A(j) & B(j) \\ \hline
0 & 0
\end{array}}\right]}
&= 
\left[
\begin{array}{c|c}
A^{D}(j) & B^{D}(j) \\ \hline
0 & I
\end{array}\right] 
\end{aligned}
\label{discreteMatrices}
\end{equation}

We can stack these matrices together to get the following lifted-vector representation \cite{Bristow06}, \cite{Schoellig12}:

\begin{equation}
\begin{aligned}
\error_L &= F\sysInput_L + \linDist_L \\
\end{aligned}
\label{liftedLTV}
\end{equation}

where the submatrices of $F$ are:

\begin{equation*}
\begin{aligned}
F_{(i,j)} &= \left \{
\begin{array}{cc}
A^{D}(i-1)\ldots A^{D}(j)B^{D}(j-1), & j < i \\ 
B^{D}(j-1), & j = i \\
0, & j > i 
\end{array} \right.
\end{aligned}
\end{equation*}

Using this \emph{input-to-output matrix} $F$ we can analyze the effects of the ILC's feedforward input $\sysInput_L = [\linInput(1), \sysInput(2), \ldots, \linInput(\numSteps)]^{\mathrm{T}}$ on the errors $\error_L = [\error(1), \error(2),\ldots,\error(\numSteps)]^{\mathrm{T}}$ using ILC terminology.

The cost functional as the optimality criterion:

\begin{equation}
\begin{aligned}
\ValueFunction(\policy) &= \int_{0}^{T} (\state - \traj)^{\mathrm{T}}Q(\state - \traj) + \linInput^{\mathrm{T}}R\linInput + (\state_T-\traj_T)^{\mathrm{T}}Q_{T}(\state_T-\traj_T)
\end{aligned}
\label{cost}
\end{equation}

can be equally discretized and stacked in lifted vector form:

\begin{equation}
\begin{aligned}
\ValueFunction_L &= \error_L^{\mathrm{T}}Q_L\error_L + \sysInput_L^{\mathrm{T}}R_L\sysInput_L
\end{aligned}
\label{costFunctional}
\end{equation}

where $Q_L, R_L \in \mathbb{R}^{N \times N}$ are of the following form:

\begin{equation*}
\begin{aligned}
 Q_L &= 
 \begin{bmatrix}
  Q & 0 & \cdots & 0 \\
  0 & Q & \cdots & 0 \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  0 & 0 & \cdots & Q_T
 \end{bmatrix} \\
 R_L &= 
  \begin{bmatrix}
   R & 0 & \cdots & 0 \\
   0 & R & \cdots & 0 \\
   \vdots  & \vdots  & \ddots & \vdots  \\
   0 & 0 & \cdots & R
  \end{bmatrix}
\end{aligned}
\end{equation*}

Most ILC update laws can be put in the following form:

\begin{equation}
\begin{aligned}
\sysInput_{k+1} = \qmatrix(\sysInput_{k} - \lmatrix\error_{k})
\end{aligned}
\label{ILCupdateForm}
\end{equation}

Gradient descent of \eqref{costFunctional} can also be put in this form:

\begin{equation}
\begin{aligned}
\sysInput_{k+1} &= \sysInput_k - \frac{\beta_k}{2} \at{\frac{\partial{\ValueFunction_L}}{\partial{\sysInput_L}}}{\sysInput_k} \\
\frac{1}{2}\frac{\partial{\ValueFunction_L}}{\partial{\sysInput_L}} &= \frac{\partial{\error_L}}{\partial{\sysInput_L}}Q_L\error_L + R_L\sysInput_L \\
\sysInput_{k+1} &= (I - \beta_kR_L)\sysInput_k - \beta_k\frac{\partial{\error_L}}{\partial{\sysInput_L}}Q_L\error_k
\end{aligned}
\label{ILCgradientDescentEq1}
\end{equation}

If the disturbances are repeating every iteration, i.e. $\frac{\partial{\linDist_L}}{\partial{\sysInput_L}} = 0$, using \eqref{liftedLTV}, we can rewrite \eqref{ILCgradientDescentEq1} as:

\begin{equation}
\begin{aligned}
\sysInput_{k+1} = (I - \beta_kR_L)\sysInput_k - \beta_kF^\mathrm{T}Q_L\error_k
\end{aligned}
\label{ILCgradientDescentEq2}
\end{equation}

where $\qmatrix = I - \beta_kR_L$ and $\lmatrix = (I - \beta_kR_L)^{-1}\beta_kF^\mathrm{T}Q_L$. In the ideal case, if $\frac{\partial{\linDist_L}}{\partial{\sysInput_L}} = 0$, and taking $\beta_1 = 1$, $R_L = 0$, this model-based ILC will converge in one step, independent of the previously applied input \cite{Bristow06}, \cite{Longman2000}.

%\todo I don't like the qbar notation
%\todo Stability and monotonic convergence.\\
%\todo Estimate $F_{est}(\error_1, \error_2, \ldots, \error_k) \neq F$.\\
%\todo Line search for $\beta_k$.\\
%\todo Noncausal ILC. 
%\todo Newton's method like update?

\subsection{Learning the Motor Primitive Parameters}

Sometimes for safety reasons the feedback law operating on the inputs may be fine-tuned to be compliant or one may not even be allowed to modify the low-level controller of the industrial robot \cite{Longman2000}. In such cases it is not possible to modify the input signals $\sysInput_L$ directly. Instead one can modify the reference trajectories that are provided to the low-level controllers. It can be shown that this is an equivalent approach to modifying the feedforward control inputs \cite{Bristow06}.

In this work we focus on modifying the parameters or the weights of the dynamic motor primitives (DMP), which acts as a \emph{kinematic policy}. For a linear system under a given linear feedback law $\sysInput = -K_u(\state - \dmp)$ we consider the following transition dynamics:

\begin{equation*}
\begin{aligned}
 \dot{\fullvec} := 
 \begin{bmatrix}
  \dot{\state} \\
  \dot{\traj} \\
  \dot{\dmp} \\
  \dot{g}
 \end{bmatrix} = 
 \underbrace{\begin{bmatrix}
  A_q - B_qK_u & 0 & B_qK_u & 0 \\
  0 & 0 & 0 & \nu(t) \\
  0  & 0  & A_s & A_g  \\
  0 & 0 & 0 & 0
 \end{bmatrix}}_{A_{\fullvec}}
 \begin{bmatrix}
   \state \\
   \traj \\
   \dmp \\
   g
  \end{bmatrix} +
  \underbrace{\begin{bmatrix}
    0 \\
    0 \\
    \basis(\phase) \\
    0
   \end{bmatrix}}_{B_{\fullvec}} \weights + \linDist(t,\weights)
\end{aligned}
\end{equation*}

where the phase $\phase$ evolves according to:

\begin{equation}
\dot{\phase} = -\tau\alpha\phase
\end{equation}

The constants $\tau$ and $\alpha$ determine the scaling and settling time respectively. 
% this needs to be rephrased perhaps.

If we introduce for this enlarged vector $\fullvec$ the following cost functional:

\begin{equation}
\begin{aligned}
J(\weights) &= \int_{0}^{T} (\state - \traj)^{\mathrm{T}}Q(\state - \traj) + \weights^{\mathrm{T}}R_w\weights + (\state_T-\traj_T)^{\mathrm{T}}Q_{T}(\state_T-\traj_T) 
\end{aligned}
\label{cost2}
\end{equation}

we can apply a weight-update form of the ILC update law \eqref{ILCupdateForm}:

\begin{equation}
\begin{aligned}
\weights_{k+1} = \qmatrix(\weights_{k} - \lmatrix\error_{k})
\end{aligned}
\label{ILCupdateFormWeights}
\end{equation}

To do this, we discretize \eqref{cost2} as in \eqref{costFunctional}:

\begin{equation}
\begin{aligned}
\ValueFunction_L &= \error_L^{\mathrm{T}}Q_L\error_L + \weights^{\mathrm{T}}R_w\weights
\end{aligned}
\label{costFunctionalWeights}
\end{equation}

Notice that now the weighting matrix $R_w \in \mathbb{R}^{m \times m}$ where $m$ is the number of basis functions used in the controls matrix $B_{\fullvec}$ or equivalently $m = \text{rank}(B_{\fullvec})$.

Gradient descent of \eqref{costFunctionalWeights} can also be put in this form:

\begin{equation}
\begin{aligned}
\weights_{k+1} &= \weights_k - \frac{\beta_k}{2} \at{\frac{\partial{\ValueFunction_L}}{\partial{\weights}}}{\weights_k} \\
\frac{1}{2}\frac{\partial{\ValueFunction_L}}{\partial{\weights}} &= \frac{\partial{\error_L}}{\partial{\weights}}Q_L\error_L + R_{\weights}\weights \\
\weights_{k+1} &= (I - \beta_kR_{\weights})\weights_k - \beta_k\frac{\partial{\error_L}}{\partial{\fullvec_L}}\at{\frac{\partial{\fullvec_L}}{\partial{\weights}}}{\fullvec_k}Q_L\error_k
\end{aligned}
\label{ILCgradientDescentWeights}
\end{equation}

If the disturbances are repeating every iteration, i.e. $\frac{\partial{\linDist_L}}{\partial{\weights}} = 0$, using \eqref{liftedLTV}, we can rewrite \eqref{ILCgradientDescentWeights} as:

\begin{equation}
\begin{aligned}
\weights_{k+1} = (I - \beta_kR_L)\weights_k - \beta_k\frac{\partial{\error_L}}{\partial{\fullvec_L}}F_{\weights}^\mathrm{T}Q_L\error_k
\end{aligned}
\label{ILCgradientDescentWeights2}
\end{equation}

where the \emph{weight-to-output matrix} $F_{\weights}$ can be written as

\begin{equation}
\begin{aligned}
\fullvec_L &= F_{\weights}\weights + \linDist_L \\
\frac{\partial{\fullvec_L}}{\partial{\weights}} &= F_{\weights}^{\mathrm{T}} \\
F_{\weights} &= \left \{
\begin{array}{cc}
A^{D}_{\fullvec}(i-1)\ldots A^{D}_{\fullvec}(j)B^{D}_{\fullvec}(j-1), & j < i \\ 
B^{D}_{\fullvec}(j-1), & j = i \\
0, & j > i 
\end{array} \right.
\end{aligned}
\label{weightToOutputMatrix}
\end{equation}

and

\begin{equation}
\begin{aligned}
\frac{\partial{\error_L}}{\partial{\fullvec_L}} =
\begin{bmatrix}
  I_{2n} & -I_{2n} & 0 & 0
 \end{bmatrix}
\end{aligned}
\end{equation}

\subsubsection{Slow learning}

\section{Results}

\subsection{Putting}

\subsection{Table Tennis}

\section{Conclusion}

\bibliographystyle{plain}
%\bibliographystyle{./IEEEtran}
%\bibliography{./IEEEabrv,./iros2015Ref}
\bibliography{./iros2015Ref}

\end{document}
