%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

%\IEEEoverridecommandlockouts % This command is only needed if you want to use the \thanks command

\overrideIEEEmargins % Needed to meet printer requirements.

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

\usepackage[latin1]{inputenc}
\usepackage{amsmath}
%\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{color}
%\usepackage{hyperref}

% theorem environment
\newtheorem{prop}{Proposition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{prop2}{Proposition}
\newtheorem{lem}{Lemma}
\newtheorem{ex}{Example}

% For algorithms
\usepackage{algorithm}
\usepackage{algorithmic}

% custom commands
\newcommand\at[2]{\left.#1\right|_{#2}} % the at differential sign
\newcommand\scalemath[2]{\scalebox{#1}{\mbox{\ensuremath{\displaystyle #2}}}} % scaling matrices

%% custom macros
\newcommand{\todo}{\textcolor{red}{TODO}} % TODO!
\newcommand{\kin}{\mathcal{T}} % used to denote inverse kinematics
\newcommand{\invKin}{\mathcal{T}^{-1}} % used to denote inverse kinematics

\newcommand{\joint}{q} % used to denote robot state in joint space
\newcommand{\state}{y} % denotes the generalized coordinates - joint space and velocity coordinates
\newcommand{\dmp}{s} % used to denote the dmp trajectory states
\newcommand{\error}{e} % difference between state and reference
\newcommand{\traj}{r} % used to denote the points on the trajectory to be tracked

\newcommand{\dist}{\epsilon} % denotes the disturbances acting on the rigid body dynamics
\newcommand{\linDist}{d} % denotes the disturbances on the LTV model

\newcommand{\sysInput}{u} % used to denote the system inputs
\newcommand{\linInput}{\tilde{u}} % denotes the LTV inputs
\newcommand{\trjInput}{\nu} % denotes the inputs on the trajectory


% % % % DMP terminology % % % %
\newcommand{\fullvec}{\psi} % full vector for state-ref-dmp-goal
\newcommand{\force}{f} % forcing term of the dmps
\newcommand{\phase}{x} % phase of the dmp
\newcommand{\weights}{w} % weights of the dmp
\newcommand{\basis}{\phi} % basis functions of the dmp as a matrix

% % % % ILC terminology % % % %
\newcommand{\qmatrix}{\Gamma} % denotes the filtering qmatrix term of Bristow et al.
\newcommand{\lmatrix}{L} % denotes the learning matrix of Bristow et al.

\newcommand{\observations}{\mathbf{y}} % used for the observed output
\newcommand{\dynamics}{f}
\newcommand{\dynamicsNominal}{f_{\mathrm{nom}}}
\newcommand{\policy}{\mathbf{\pi}}
\newcommand{\ValueFunction}{J}
\newcommand{\episode}{k} % used for episode number

\newcommand{\totalTime}{T} % total time duration 
\newcommand{\numSteps}{N} % total number of time steps
\newcommand{\numepisode}{K} % total number of episodes

\newcommand{\threshold}{\epsilon}
\newcommand{\alg}{\emph{wILC}}
\newcommand{\dataset}{E}

% Set the paths where all figures are taken from:
\graphicspath{{Pictures/}}
\mathtoolsset{showonlyrefs} 
\newcommand{\includesvg}[1]{%
% \executeiffilenewer{#1.svg}{#1.pdf}%
% {inkscape -z -D --file=#1.svg %
% --export-pdf=#1.pdf --export-latex}%
 \input{#1.pdf_tex}%
}

\title{\LARGE \bf
Optimal Striking Movement Generation \& Representation
}

\author{Okan Ko\c c$^{1}$, Guilherme Maeda$^{2}$, Gerhard Neumann${^2}$, Jan Peters$^{1,2}$% <-this % stops a space 
\\
{\tt\small \{okan.koc, jan.peters\}@tuebingen.mpg.de}%
\thanks{$^{1}$Max Planck Institute for Intelligent Systems,
        Spemannstr. 38, 72076 Tuebingen, Germany}
\thanks{$^{2}$Technische Universitaet Darmstadt, FG Intelligente Autonome Systeme
        Hochschulstr. 10, 64289 Darmstadt, Germany}
}

\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

Motivated by the recent advances of Reinforcement Learning (RL) applications in complex robotics tasks we consider in this article the movement generation and representation of optimal striking motions. More precisely, we present an Iterative Learning Control \cite{Bristow06} based approach to track reference trajectories by adapting the weights of dynamic movement primitives. This way, unlike the existing RL approaches, we ensure the optimality of the converged kinematic policies. We show the performance of the approach in two hitting tasks: generating the putting motions in golf and striking motions in robotic table tennis.

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\input{introduction}
\input{problemstatement}
\input{algorithm}
\input{experiments}
\input{conclusion}

\bibliographystyle{plain}
%\bibliographystyle{./IEEEtran}
%\bibliography{./IEEEabrv,./iros2015Ref}
\bibliography{./iros2015Ref}

\end{document}
