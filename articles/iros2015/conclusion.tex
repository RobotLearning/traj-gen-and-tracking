\section{CONCLUSION}\label{conclusion}

In this paper we presented a novel Iterative Learning Control algorithm that tracks trajectories by adapting the weights of dynamic movement primitives. Weights are adapted after each episode by using a Levenberg-Marquardt type update rule on the deviations from the reference trajectories. These reference trajectories are generated in the joint space of the robot and enable the robot to execute optimally striking motions. We show two example experiments where we evaluate the performance of the approach in putting in golf and in ball-hitting with a racket in robotic table tennis. 

Reference trajectories are used in our approach only as a way to end up at the desired hitting states within the desired time frame. We are currently evaluating new ways within the optimal control perspective where the dependence on this sometimes arbitrary reference trajectory diminishes over the iteration domain, as the robot gets more confident in the hitting motion.

Finally a natural extension of the DMP representation is the generalization ability of these differential equations to different hitting motions and trajectories. We think that with our method, a stochastic approach to guide exploration is missing, and it is this that restricts the generalization ability of the proposed algorithm. By extending our framework to include the Probabilistic Movement Primitives~\cite{Paraschos13} we hope to increase the generalization ability and leverage the probabilistic logic of these movement primitives.

%\section*{APPENDIX}
%
%Appendixes should appear before the acknowledgment.
%
%\section*{ACKNOWLEDGMENT}
%
%The preferred spelling of the word ÒacknowledgmentÓ in America is without an ÒeÓ after the ÒgÓ. Avoid the stilted expression, ÒOne of us (R. B. G.) thanks . . .Ó  Instead, try ÒR. B. G. thanksÓ. Put sponsor acknowledgments in the unnumbered footnote on the first page.