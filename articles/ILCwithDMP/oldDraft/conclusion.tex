\section{CONCLUSION AND FUTURE WORK}\label{conclusion}

In this paper we presented a novel Iterative Learning Control algorithm that tracks trajectories by adapting the weights of Dynamic Movement Primitives. Weights are adapted after each episode by using a Levenberg-Marquardt type update rule on the deviations from the reference trajectories. These reference trajectories are generated in the joint space of the robot and enable the robot to execute optimal striking motions. We show two experiments where we evaluate the performance of the approach: putting in golf and ball-hitting in robotic table tennis. 

Reference trajectories are used in our approach only as a way to end up at the desired hitting states within the desired time period. We are currently evaluating new ways within the optimal control perspective where the dependence on this sometimes arbitrary reference trajectory diminishes over the iteration domain, as the robot gets more confident in the hitting task.

Finally a natural extension of the DMP representation is the generalization ability of these differential equations to different hitting motions and trajectories. We think that with our method, a stochastic approach to guide exploration is missing, and it is this that restricts the generalization ability of the proposed algorithm. By extending our framework to include the Probabilistic Movement Primitives~\cite{Paraschos13} we hope to increase the generalization ability of ILC and learn to track a whole \emph{distribution} of movement primitives.

%\section*{APPENDIX}
%
%Appendixes should appear before the acknowledgment.
%
%\section*{ACKNOWLEDGMENT}
%
%The preferred spelling of the word ÒacknowledgmentÓ in America is without an ÒeÓ after the ÒgÓ. Avoid the stilted expression, ÒOne of us (R. B. G.) thanks . . .Ó  Instead, try ÒR. B. G. thanksÓ. Put sponsor acknowledgments in the unnumbered footnote on the first page.